<!doctype html>
<html lang="en-us">
    <head>
        <title>stream : Real-time Whisper transcription in WebAssembly</title>
        <link rel="stylesheet" href="styles.css">
         <script src="https://code.jquery.com/jquery-3.6.4.min.js"
         integrity="sha256-oP6HI9z1XaZNBrJURtCoUT5SUnxFr8s3BzRl+cbzUq8="
         crossorigin="anonymous"></script>
        <!--  TOKEN FOR GITHUB -->
         <!-- <meta http-equiv="origin-trial" content="Atny3N60DQ2VmUDTOosUDLiwpTRbuSgMZGV3jOdpXNLLCfHG/RDbIvsdWeWrwWeKfI2n3AaWF6xiUHQmgMzuugYAAACBeyJvcmlnaW4iOiJodHRwczovL3NraWxsaW5nc2hhcmsuZ2l0aHViLmlvOjQ0MyIsImZlYXR1cmUiOiJVbnJlc3RyaWN0ZWRTaGFyZWRBcnJheUJ1ZmZlciIsImV4cGlyeSI6MTcwOTg1NTk5OSwiaXNTdWJkb21haW4iOnRydWV9"> -->
         <!-- TOKEN FOR PORT 5872 -->
         <meta http-equiv="origin-trial" content="AtL1nQI0P4o0J+7BIUnXmUZbTKAzhbw61i7rG+bnhTOBdptUUsHShOokVnusoHtmIjX7gUXzGL8DvG4SRZz1uA8AAABgeyJvcmlnaW4iOiJodHRwOi8vMTI3LjAuMC4xOjU4NzIiLCJmZWF0dXJlIjoiVW5yZXN0cmljdGVkU2hhcmVkQXJyYXlCdWZmZXIiLCJleHBpcnkiOjE3MDk4NTU5OTl9">

         <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.js"></script>
         <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.7/dist/bundle.min.js"></script>
         <script type="text/javascript" src="https://cdn.skypack.dev/d3@7"></script>
        
    </head>
    <body>       
        <div id="status">Recording not started</div>
        <div id="listening"></div>

        <div id="main-container">
            <b>STREAM : Real-time Whisper transcription in WebAssembly</b>

            <br><br>
            <p id="welcome">Select the model you would like to use .... You can start speaking Once the model is initialized</p>    
            

            <br><br>
            
            <br><br>

            <div id="model-whisper">

               <p class="model-type"id="whisper-model-label" >Whisper model: </p> <span id="model-whisper-status"></span> <br>

                <button id="fetch-whisper-tiny-en" onclick="loadWhisper('tiny.en')">tiny.en (75 MB)</button>
                <button id="fetch-whisper-base-en" onclick="loadWhisper('base.en')">base.en (142 MB)</button>
                <br><br>

                <p class="model-type" id="quantized-model-label">Quantized models:</p>

                <button id="fetch-whisper-tiny-en-q5_1"   onclick="loadWhisper('tiny-en-q5_1')">tiny.en (Q5_1, 31 MB)</button>
                <button id="fetch-whisper-base-en-q5_1"   onclick="loadWhisper('base-en-q5_1')">base.en (Q5_1, 57 MB)</button>

                <span id="fetch-whisper-progress"></span>

                <!--
                    <input type="file" id="file" name="file" onchange="loadFile(event, 'whisper.bin')" />
                -->
            </div>

            <br>

            <!-- <div id="input">
                <button id="start"  onclick="onStart()" disabled>Start</button>
                <button id="stop"   onclick="onStop()" disabled>Stop</button>
                <button id="clear"  onclick="clearCache()">Clear Cache</button>
            </div> -->

            <br> 
            <br><br><br><br><br>

            <div id="state">
                Status: <b><span id="state-status">not started</span></b>

                <pre id="state-transcribed">[The transcribed text will be displayed here]</pre>
            </div>

            <hr>

            <div id="greeting-container">
                <p id="greeting-text">Yes, Sir! What can I do for you?</p>
            </div>

            <!-- Debug output: -->
            <!-- <textarea id="output" rows="20"></textarea> -->

            <br>

            <!-- <b>Troubleshooting</b> -->

            <br><br>

            <!-- The page does some heavy computations, so make sure: -->

            <!-- <ul>
                <li>To use a modern web browser (e.g. Chrome, Firefox)</li>
                <li>To use a fast desktop or laptop computer (i.e. not a mobile phone)</li>
                <li>Your browser supports WASM <a href="https://webassembly.org/roadmap/">Fixed-width SIMD</a></li>
            </ul> -->

            <!-- <div class="cell-version">
                <span>
                    |
                    Build time: <span class="nav-link">Sun Dec 10 23:17:52 2023</span> |
                    Commit hash: <a class="nav-link" href="https://github.com/ggerganov/whisper.cpp/commit/6335933a">6335933a</a> |
                    Commit subject: <span class="nav-link">cmake : Fix bug in httplib.h for mingw (#1615)</span> |
                    <a class="nav-link" href="https://github.com/ggerganov/whisper.cpp/tree/master/examples/stream.wasm">Source Code</a> |
                </span>
            </div> -->
        </div>


        <script type="text/javascript" src="helpers.js"></script>
        <!-- <script type="module">import { interpolateInferno } from "https://cdn.skypack.dev/d3-scale-chromatic@3" </script> -->
        <script type="text/javascript" src="https://cdn.skypack.dev/d3-scale-chromatic@3"></script>
        <script type="module">
            import { interpolateInferno } from 'https://cdn.skypack.dev/d3@7';

            async function gradient() {
                // Get the color scale from D3
                const colorScale = interpolateInferno;

                // Calculate the background color based on the probability value
                const gradientValue = probs.isSpeech / 2; // Adjust as needed
                const backgroundColor = colorScale(gradientValue);

                // Apply the background color with the gradient effect
                document.body.style.backgroundColor = backgroundColor;
                document.body.classList.add('gradient-effect');

                // ... existing code ...

                // Remove gradient effect after a certain time (adjust as needed)
                setTimeout(() => {
                    document.body.classList.remove('gradient-effect');
                    document.body.style.backgroundColor = ''; // Reset background color
                }, 500);
            }

        </script>
        <script type="text/javascript">
            // <script type="module">import { interpolateInferno } from "https://cdn.skypack.dev/d3-scale-chromatic@3"
                // const output_area = document.getElementById('state-transcribed');
            // web audio context
            var context = null;

            // audio data
            var audio = null;
            var audio0 = null;

            // the stream instance
            var instance = null;

            // model name
            var model_whisper = null;

            var Module = {
                print: printTextarea,
                // print: printTextarea2,
                printErr: printTextarea,
                setStatus: function(text) {
                    printTextarea('js: ' + text);
                },
                monitorRunDependencies: function(left) {
                },
                preRun: function() {
                    printTextarea('js: Preparing ...');
                },
                postRun: function() {
                    printTextarea('js: Initialized successfully!');
                },
            };

            //
            // fetch models
            //

            let dbVersion = 1
            let dbName    = 'whisper.ggerganov.com';
            let indexedDB = window.indexedDB || window.mozIndexedDB || window.webkitIndexedDB || window.msIndexedDB

            function storeFS(fname, buf) {
                // write to WASM file using FS_createDataFile
                // if the file exists, delete it
                try {
                    Module.FS_unlink(fname);
                    // FS.unlink(fname);
                } catch (e) {
                    // ignore
                   
                }

                Module.FS_createDataFile("/", fname, buf, true, true);
                // FS.createDataFile("/", fname, buf, true, true);


                printTextarea('storeFS: stored model: ' + fname + ' size: ' + buf.length);

                document.getElementById('model-whisper-status').innerHTML = 'Model Loaded :  "' + model_whisper + '"';

                // if (model_whisper != null) {
                //     document.getElementById('start').disabled = false;
                //     document.getElementById('stop' ).disabled = true;
                // }
            }

            function loadWhisper(model) {
                document.getElementById('model-whisper-status').classList.add('highlighted');
                document.getElementById('welcome').style.display = 'none';
                let urls = {
                    'tiny.en': './ggml-model-whisper-tiny.en.bin',
                    'base.en': 'http://127.0.0.1:5872/03_vad_wasm/ggml-model-whisper-base.en.bin',

                    'tiny-en-q5_1':  'https://whisper.ggerganov.com/ggml-model-whisper-tiny.en-q5_1.bin',
                    'base-en-q5_1':  'https://whisper.ggerganov.com/ggml-model-whisper-base.en-q5_1.bin',
                };

                let sizes = {
                    'tiny.en': 75,
                    'base.en': 142,

                    'tiny-en-q5_1':   31,
                    'base-en-q5_1':   57,
                };

                let url     = urls[model];
                let dst     = 'whisper.bin';
                let size_mb = sizes[model];

                model_whisper = model;

                document.getElementById('whisper-model-label').style.display = 'none';
                document.getElementById('quantized-model-label').style.display = 'none';
                document.getElementById('fetch-whisper-tiny-en').style.display = 'none';
                document.getElementById('fetch-whisper-base-en').style.display = 'none';

                document.getElementById('fetch-whisper-tiny-en-q5_1').style.display = 'none';
                document.getElementById('fetch-whisper-base-en-q5_1').style.display = 'none';

                document.getElementById('model-whisper-status').innerHTML = 'loading "' + model + '" ... ';

                cbProgress = function(p) {
                    let el = document.getElementById('fetch-whisper-progress');
                    el.innerHTML = Math.round(100*p) + '%';
                };

                cbCancel = function() {
                    var el;
                    // el = document.getElementById('fetch-whisper-tiny-en'); if (el) el.style.display = 'inline-block';
                    // el = document.getElementById('fetch-whisper-base-en'); if (el) el.style.display = 'inline-block';

                    // el = document.getElementById('fetch-whisper-tiny-en-q5_1'); if (el) el.style.display = 'inline-block';
                    // el = document.getElementById('fetch-whisper-base-en-q5_1'); if (el) el.style.display = 'inline-block';

                    el = document.getElementById('model-whisper-status');  if (el) el.innerHTML = '';
                };

                loadRemote(url, dst, size_mb, cbProgress, storeFS, cbCancel, printTextarea);
            }

            //
            // microphone
            //

            const kSampleRate = 16000;
            const kRestartRecording_s = 120;
            const kIntervalAudio_ms = 5000; // pass the recorded audio to the C++ instance at this rate

            var mediaRecorder = null;
            var doRecording = false;
            var startTime = 0;

            window.AudioContext = window.AudioContext || window.webkitAudioContext;
            window.OfflineAudioContext = window.OfflineAudioContext || window.webkitOfflineAudioContext;

            function stopRecording() {
                Module.set_status("paused");
                doRecording = false;
                audio0 = null;
                audio = null;
                context = null;
            }


            
            ////////////////////////////////
            var nLines = 0;
            var intervalUpdate = null;
            var transcribedAll = '';
        //   import { interpolateInferno } from "https://cdn.skypack.dev/d3-scale-chromatic@3" 
        
        
        function showGreeting() 
        {
            // Show greeting container
            const greetingContainer = document.getElementById('greeting-container');
            greetingContainer.classList.add('show');

            // Hide greeting after 3 seconds (adjust as needed)
            // setTimeout(() => {
            //     greetingContainer.classList.remove('show');
            // }, 3000);
        }     
        async function main() 
        {

        console.log('entered MAIN ////////////////////');
        // transcribedAll = '';

        const statusElement = document.getElementById('status');
        const resultContainer = document.getElementById('resultContainer');
        const transcriptionResult = document.getElementById('transcriptionResult');
        const detectedLanguage = document.getElementById('detectedLanguage');

        //////////////////////////////////////////

        // let all_text = "";

        const myvad = await vad.MicVAD.new({

            

            onSpeechStart: () =>{
                statusElement.textContent = 'Recording started';
            },
            // onFrameProcessed: (probs) => {
            //     gradient();
            // },
        
            
            onSpeechEnd: (audio) => {
                if (!instance) {
                    instance = Module.init('whisper.bin');

                    if (instance) {
                        printTextarea("js: whisper initialized, instance: " + instance);
                    }
                }

                if (!instance) {
                    printTextarea("js: failed to initialize whisper");
                    return;
                }
                // const wavBuffer = vad.utils.encodeWAV(arr)
                // const base64 = vad.utils.arrayBufferToBase64(wavBuffer)
                statusElement.textContent = 'Recording finished';
                // stopRecording();
                var audioAll = new Float32Array(audio0 == null ? audio.length : audio0.length + audio.length);
                            if (audio0 != null) {
                                audioAll.set(audio0, 0);
                            }
                            audioAll.set(audio, audio0 == null ? 0 : audio0.length);

                            if (instance) {
                                Module.set_audio(instance, audioAll);
                            }
//// start recording called
if (!context) {
                    context = new AudioContext({
                        sampleRate: kSampleRate,
                        channelCount: 1,
                        echoCancellation: false,
                        autoGainControl:  true,
                        noiseSuppression: true,
                    });
                }
                            Module.set_status("");

                            doRecording = true;
                            startTime = Date.now();

                            var chunks = [];
                            var stream = null;

                            //// start recording ended
                    
                intervalUpdate = setInterval(function() {
                    var transcribed = Module.get_transcribed();

                    if (transcribed != null && transcribed.length > 1) {
                        transcribedAll += transcribed + '\n';
                        nLines++;

                        // if more than 10 lines, remove the first line
                        if (nLines > 10) {
                            var i = transcribedAll.indexOf('\n');
                            if (i > 0) {
                                transcribedAll = transcribedAll.substring(i + 4);
                                nLines--;
                            }
                        }
                    }

                    document.getElementById('state-status').innerHTML = Module.get_status();
                    // document.getElementById('state-transcribed').innerHTML = transcribedAll;
                }, 100);
                        stopRecording();
                        console.log('recording stopped in main')      
                        console.log(transcribedAll)
                searchString = "Hello"
                if (transcribedAll.toLowerCase().includes("hello"))
                {
                    console.log('got it ');
                    console.log('got it ');
                    console.log('got it ');
                    console.log('got it ');

                    // transcribedAll = '';
                    showGreeting();
                    secondary()
                }
                else if (transcribedAll.toLowerCase().includes("ok"))
                {
                    console.log('got it ');
                    console.log('got it ');
                    console.log('got it ');
                    console.log('got it ');

                    secondary()
                }
                else if (transcribedAll.toLowerCase().includes("google"))
                {
                    console.log('got it ');
                    console.log('got it ');
                    console.log('got it ');
                    console.log('got it ');

                    secondary()
                }
                
                // searchString= "Okay"
                // stopRecording();
                // else 
                // {
                //     console.log("The text does not contain the specified string.");
                // }


            },
        });

        myvad.start();
        // const listeningstatus = document.getElementById('listening');
        // listeningstatus.textContent = myvad.listening();

    }
        
    async function secondary()
    {   
        console.log("entered secondary //////////////////////")
        transcribedAll = '';
        var cnt = 0 ;
        const statusElement = document.getElementById('status');
        const resultContainer = document.getElementById('resultContainer');
        const transcriptionResult = document.getElementById('transcriptionResult');
        const detectedLanguage = document.getElementById('detectedLanguage');


        const myvad = await vad.MicVAD.new({

                onSpeechStart: () => {
                    statusElement.textContent = 'Recording started INSIDE SECONDARY';
                        },


                onSpeechEnd: (audio) => {
                    cnt = 1;
                    if (!instance) {
                        instance = Module.init('whisper.bin');

                        if (instance) {
                            printTextarea("js: whisper initialized, instance: " + instance);
                        }
                    }

                    if (!instance) {
                        printTextarea("js: failed to initialize whisper");
                        return;
                    }
                    // const wavBuffer = vad.utils.encodeWAV(arr)
                    // const base64 = vad.utils.arrayBufferToBase64(wavBuffer)
                    statusElement.textContent = 'Recording finished INSIDE SECONDARY';
                    // stopRecording();
                    var audioAll = new Float32Array(audio0 == null ? audio.length : audio0.length + audio.length);
                                if (audio0 != null) {
                                    audioAll.set(audio0, 0);
                                }
                                audioAll.set(audio, audio0 == null ? 0 : audio0.length);

                                if (instance) {
                                    Module.set_audio(instance, audioAll);
                                }
                //// start recording called
                if (!context) {
                        context = new AudioContext({
                            sampleRate: kSampleRate,
                            channelCount: 1,
                            echoCancellation: false,
                            autoGainControl:  true,
                            noiseSuppression: true,
                        });
                    }
                                Module.set_status("");

                                doRecording = true;
                                startTime = Date.now();

                                var chunks = [];
                                var stream = null;

                                // start recording ended
                        
                    intervalUpdate = setInterval( function() 
                    {
                        var transcribed = Module.get_transcribed();

                        if (transcribed != null && transcribed.length > 1) {
                            transcribedAll += transcribed + '\n';
                            nLines++;

                            // if more than 10 lines, remove the first line
                            if (nLines > 10) {
                                var i = transcribedAll.indexOf('\n');
                                if (i > 0) {
                                    transcribedAll = transcribedAll.substring(i + 4);
                                    nLines--;
                                }
                            }
                        }

                        document.getElementById('state-status').innerHTML = Module.get_status();
                        console.log('time to print transcribedAll');
                        printTextarea(transcribedAll);
                        console.log(transcribedAll);
                        document.getElementById('state-transcribed').textContent = transcribedAll;
                    }, 100);
                    stopRecording();         
                    
                    // searchString = "Hello"
                    // if (transcribedAll.includes(searchString)) 
                    // {
                    //     secondary()
                    // }

                   

                    // else 
                    // {
                    //     console.log("The text does not contain the specified string.");
                    // }


                },
                });

                myvad.start();
                // const listeningstatus = document.getElementById('listening');
                // listeningstatus.textContent = myvad.listening();
                if(cnt == 1)
                    {   
                        console.log('printing from secondary')
                        console.log(transcribedAll);
                        main()
                        // return ;
                    }


    }
    main();


            /////////////////////////////////

        </script>
        <script type="text/javascript" src="stream.js"></script>
    </body>
</html>
